{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa86Hx3w1w81CTMkN4hwg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42ee3f5c39ef4ae49560d079d99e4e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21775e8949374978a3363208dc93a719",
              "IPY_MODEL_cff599adca394d2ba8856d00d17f4c75",
              "IPY_MODEL_002ceb96435e4649b2c1ae7e0cbefb71"
            ],
            "layout": "IPY_MODEL_63785a2b5a6e4d51bc8e0eac7a24b403"
          }
        },
        "21775e8949374978a3363208dc93a719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e298fa3361c4409c8c70a708a9aa4a37",
            "placeholder": "​",
            "style": "IPY_MODEL_311a2d1e55c94fd4993116265c7f1912",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "cff599adca394d2ba8856d00d17f4c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872045da89b24892bddec2d2d951da65",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_163ba21c09cd4c5d8d6c462c7eeba227",
            "value": 570
          }
        },
        "002ceb96435e4649b2c1ae7e0cbefb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1987ecf3fb974d0ea142bf3ce87fb736",
            "placeholder": "​",
            "style": "IPY_MODEL_3b18f65f340a4c70a7bf7003fa557963",
            "value": " 570/570 [00:00&lt;00:00, 6.63kB/s]"
          }
        },
        "63785a2b5a6e4d51bc8e0eac7a24b403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e298fa3361c4409c8c70a708a9aa4a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311a2d1e55c94fd4993116265c7f1912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "872045da89b24892bddec2d2d951da65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "163ba21c09cd4c5d8d6c462c7eeba227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1987ecf3fb974d0ea142bf3ce87fb736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b18f65f340a4c70a7bf7003fa557963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "410fe4c1f1d34dfdb17631111c073903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d18341ec52341d0a6f994ef4bd61f99",
              "IPY_MODEL_660f6aaef6fc472da0c49b6431eb884f",
              "IPY_MODEL_da75cdf4a1b744c3bc3185543b9f4875"
            ],
            "layout": "IPY_MODEL_36e19ea797924f9886d8e6a65d819f10"
          }
        },
        "7d18341ec52341d0a6f994ef4bd61f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94e00975c1764e09aea288808b7117a4",
            "placeholder": "​",
            "style": "IPY_MODEL_e08e3da649314ee9b0c8cdf12003932b",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "660f6aaef6fc472da0c49b6431eb884f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4719a10aa75e45608f7e841e18cf85b6",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a6880a125324d7e822db99cd5167b46",
            "value": 440449768
          }
        },
        "da75cdf4a1b744c3bc3185543b9f4875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_058531d3dfc74c73950d571f428bef8e",
            "placeholder": "​",
            "style": "IPY_MODEL_1b8811a1fdae4adc855cf180c7fc402d",
            "value": " 440M/440M [00:05&lt;00:00, 86.2MB/s]"
          }
        },
        "36e19ea797924f9886d8e6a65d819f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e00975c1764e09aea288808b7117a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e08e3da649314ee9b0c8cdf12003932b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4719a10aa75e45608f7e841e18cf85b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a6880a125324d7e822db99cd5167b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "058531d3dfc74c73950d571f428bef8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8811a1fdae4adc855cf180c7fc402d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micheldc55/Deep-Learning/blob/main/self_attention_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUOTT2rPSqBh",
        "outputId": "d2936ddd-cca9-4b0e-a43b-d489f5ffade7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lQXpbBheVBXP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Attention in BERT's first layer"
      ],
      "metadata": {
        "id": "4x54ORWITt-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QcC4xI4pSX4c"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155,
          "referenced_widgets": [
            "42ee3f5c39ef4ae49560d079d99e4e94",
            "21775e8949374978a3363208dc93a719",
            "cff599adca394d2ba8856d00d17f4c75",
            "002ceb96435e4649b2c1ae7e0cbefb71",
            "63785a2b5a6e4d51bc8e0eac7a24b403",
            "e298fa3361c4409c8c70a708a9aa4a37",
            "311a2d1e55c94fd4993116265c7f1912",
            "872045da89b24892bddec2d2d951da65",
            "163ba21c09cd4c5d8d6c462c7eeba227",
            "1987ecf3fb974d0ea142bf3ce87fb736",
            "3b18f65f340a4c70a7bf7003fa557963",
            "410fe4c1f1d34dfdb17631111c073903",
            "7d18341ec52341d0a6f994ef4bd61f99",
            "660f6aaef6fc472da0c49b6431eb884f",
            "da75cdf4a1b744c3bc3185543b9f4875",
            "36e19ea797924f9886d8e6a65d819f10",
            "94e00975c1764e09aea288808b7117a4",
            "e08e3da649314ee9b0c8cdf12003932b",
            "4719a10aa75e45608f7e841e18cf85b6",
            "0a6880a125324d7e822db99cd5167b46",
            "058531d3dfc74c73950d571f428bef8e",
            "1b8811a1fdae4adc855cf180c7fc402d"
          ]
        },
        "id": "n7x1tS95SfCq",
        "outputId": "ed61324d-4ccf-419f-c849-824b405f7844"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42ee3f5c39ef4ae49560d079d99e4e94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "410fe4c1f1d34dfdb17631111c073903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen below, BERT has 12 attention layers in the enconder phase in total. Each of this attention layers can be though of as a creating a deeper and more context-aware representation of the input, based on the raw values of the input as individual tokens."
      ],
      "metadata": {
        "id": "E_ikqHT_T6hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.encoder.layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-yOGRcoSoHD",
        "outputId": "6217ab90-9f1e-4d71-92ac-2eea6bedfed6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The attention mechanism breaks the initial input into 3 matrices Q, K and V. These 3 matrices are used to generate a representation of how much \"attention\" should be payed to each of the input tokens, based on the embeddings for each token on its own."
      ],
      "metadata": {
        "id": "tuqv4-GsUnym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.encoder.layer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IShrwUM_S6Ut",
        "outputId": "ae523e79-c3f6-4021-8dfb-aa8c42499d93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertLayer(\n",
              "  (attention): BertAttention(\n",
              "    (self): BertSelfAttention(\n",
              "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (output): BertSelfOutput(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (intermediate): BertIntermediate(\n",
              "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    (intermediate_act_fn): GELUActivation()\n",
              "  )\n",
              "  (output): BertOutput(\n",
              "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example of the Q, K and V matrices given an input\n",
        "\n",
        "Let's create an input phrase, for example: \"I am short\". Now let's create the corresponding spaces Q, K and V for this tokens, and see how that would play out. The input has 3 words (and we will treat words like tokens for now), so we will have our input \"X\" be 3 x 9 where 9 is just our vocabulary, our \"number of possible words\", if you will.\n",
        "\n",
        "**Note:** In reality, words will actually be tokens, and the vocabulary will be way larger than 9, but 9 will serve as a good way to show how we would proceed if this was the real transformer."
      ],
      "metadata": {
        "id": "6VZW7oXkVZCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"I am short\""
      ],
      "metadata": {
        "id": "_z2c_3UBS9md"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This would get broken down to:"
      ],
      "metadata": {
        "id": "eDm22YUHZ-_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|       | d1    | d2     | d3 | d4 | d5 | d6  | d7 | d8 | d9    |\n",
        "|-------|-------|--------|----|----|----|-----|----|----|--------|\n",
        "| I     | 0.8137| 0.7803 | ...| ...| ...| ... | ...| ...| 0.117  |\n",
        "| am    | 0.1000| 0.2150 | ...| ...| ...| ... | ...| ...| 0.701  |\n",
        "| short | 0.1770|-0.7047 | ...| ...| ...| ... | ...| ...| -0.321 |"
      ],
      "metadata": {
        "id": "VgRZmcSva-hB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where ${d_i}$ are the different dimensions of each input token in positinal encoding embedding space. Check the [attention is all you need](https://arxiv.org/pdf/1706.03762.pdf) paper for a reference to the actual architecture image."
      ],
      "metadata": {
        "id": "TL8_KoRnbKuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use PyTorch to build such matrix and go over the process that would happen inside a Transformer. We will call our inputs \"X\", and our Query, Key and Value matrices Q, K and V respectively, just like the paper does.\n",
        "\n",
        "The attention mechanism is based on calculating the attention value that should be applied to each value in the \"Value\" space. If we think of V as if it holds the information of the meaning of the words independently of their context, we want to train a normalized attention matrix ${\\frac{QK^{T}}{\\sqrt{d_{k}}}}$ that measures what tokens should be payed the most attention to. The output is converted to probabilities using a softmax transformation.\n",
        "\n",
        "The attention matrix will then multiply the Value matrix to convert the context agnostic \"V\" matrix to a context-aware \"V\" matrix. So, the attention applied to the V matrix can be written as:\n",
        "\n",
        "$${softmax(\\frac{QK^{T}}{\\sqrt{d_{k}}})V}$$"
      ],
      "metadata": {
        "id": "BZCvn7PPbxzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need three extra matrices that will not be discussed for now. This are the weights matrices, and they multiply or input \"X\" and transform it to Q, K and V respectively. They are generally written as ${W^{Q}}$, ${W^{K}}$ and ${W^{V}}$"
      ],
      "metadata": {
        "id": "YgNL6JkDeXWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So imagine that the dimensions of each token in the positional embedding space is:"
      ],
      "metadata": {
        "id": "d8sHZi1MeqXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.Tensor([[0.8137, 0.7803, 0.0972, 0.1619, 0.6793, 0.0919, 0.4634, 0.5565, 0.117],\n",
        "        [0.1000, 0.2150, 0.5824, 0.5941, 0.7734, 0.1016, 0.9998, 0.1266, 0.701],\n",
        "        [0.1770, -0.7047, 0.7806, 0.4591, 0.3710, 0.1028, 0.0787, 0.0687, -0.321]])\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbPVtbDRZ-Tk",
        "outputId": "7114a18f-c13f-41d8-df5a-0ba375d911e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8137,  0.7803,  0.0972,  0.1619,  0.6793,  0.0919,  0.4634,  0.5565,\n",
              "          0.1170],\n",
              "        [ 0.1000,  0.2150,  0.5824,  0.5941,  0.7734,  0.1016,  0.9998,  0.1266,\n",
              "          0.7010],\n",
              "        [ 0.1770, -0.7047,  0.7806,  0.4591,  0.3710,  0.1028,  0.0787,  0.0687,\n",
              "         -0.3210]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, \"I\" in the initial embedding space is represented by the 9 dimensional vector: [0.8137,  0.7803,  0.0972,  0.1619,  0.6793,  0.0919,  0.4634,  0.5565, 0.1170]\n",
        "\n",
        "\"am\" in the same space is represented by the 9 dimensional vector: [0.1000,  0.2150,  0.5824,  0.5941,  0.7734,  0.1016,  0.9998,  0.1266, 0.7010]\n",
        "\n",
        "And \"short\" is represented by the vector: [0.1770, -0.7047,  0.7806,  0.4591,  0.3710,  0.1028,  0.0787,  0.0687, -0.3210]"
      ],
      "metadata": {
        "id": "T4FLGeeagKKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we imagine we want to create a representation of the text in a 4-dimensional space, then our Weight vectors (${W^{i}}$) will be of the shape 9x4.\n",
        "\n",
        "So the shape of Q, K and V, will be 3 x 4, since they will be the product of multiplying X times their corresponding weight matrix, and we know the dimensions of both. Let's create some artificial Q, K and V matrices:"
      ],
      "metadata": {
        "id": "lALeHxU9hRqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = torch.Tensor([[0.023, 0.7144, 1.03, 0.576], [0.903, 0.1474, -0.338, -0.765], [0.576, -0.7144, 0.03, -0.076]])\n",
        "\n",
        "K = torch.Tensor([[0.5224, -0.1328, 0.9169, 0.5317], [0.3535, 0.7698, -0.2965, 0.2669], [0.3864, 0.5015, 0.5557, -0.1671]])\n",
        "\n",
        "V = torch.Tensor([[0.7467, 0.0360, -0.5847, 0.0370], [1.509, 0.8009, 0.7957, 0.0151], [0.4343, 0.9003, 0.3387, 0.2031]])"
      ],
      "metadata": {
        "id": "RXgtl5zofLJf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically, Q, K and V are the representations of the input embedding vectors in the Q space, K space and V spaces respectively. The V space attempts to retain information about the individual tokens while the other two combine to generate a representation of the tokens in their context and will be the building blocks for the attention mechanism applied to V.\n",
        "\n",
        "Let's now build ${QK^{T}}$"
      ],
      "metadata": {
        "id": "bozragBTjLvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K_t = torch.transpose(K, 0, 1)\n",
        "K_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfONJsXUicnK",
        "outputId": "a876a50d-ebbb-4bfb-b7da-ac72613d77ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5224,  0.3535,  0.3864],\n",
              "        [-0.1328,  0.7698,  0.5015],\n",
              "        [ 0.9169, -0.2965,  0.5557],\n",
              "        [ 0.5317,  0.2669, -0.1671]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_kt = torch.mm(Q, K_t)\n",
        "q_kt  # This is a 3x3 matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0EyUXQziiJK",
        "outputId": "20dea4cc-0eac-4486-d6e2-6560c0eb0f62"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1678,  0.4064,  0.8433],\n",
              "        [-0.2645,  0.3287,  0.3628],\n",
              "        [ 0.3829, -0.3755, -0.1063]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch allows us to calculate the attention matrix using a few simple functions:"
      ],
      "metadata": {
        "id": "WHkNhN52kJbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_space = q_kt.shape[1]\n",
        "\n",
        "att_before_softmax = torch.div(q_kt, torch.sqrt(torch.tensor(embedding_space)))\n",
        "\n",
        "att_before_softmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQdKGkEKjniE",
        "outputId": "e405b8a5-0664-449f-cd18-7a9e57b70ea9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6742,  0.2346,  0.4869],\n",
              "        [-0.1527,  0.1898,  0.2095],\n",
              "        [ 0.2211, -0.2168, -0.0614]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that for the word \"I\" for example (first row), the values for the attention add up to more than one. This is because we haven't applied the softmax function. Let's see what I mean, below are the sums at row level (note they don't necessarily add up to 1.0). I'm only reshaping the tensor so that each sum is at the same position as the row it represents in the above matrix."
      ],
      "metadata": {
        "id": "HO1BEE3yll8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(att_before_softmax, dim=1).reshape(-1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f36D2WxYlXPE",
        "outputId": "d217f66f-7266-46fa-b87d-26ffb8b01ff8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3957],\n",
              "        [ 0.2466],\n",
              "        [-0.0571]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_matrix = torch.softmax(att_before_softmax, dim=1)\n",
        "\n",
        "attn_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3v6G_MQlZae",
        "outputId": "dfda7d1b-6641-4482-8bb7-a27ebd07aabe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4043, 0.2605, 0.3352],\n",
              "        [0.2601, 0.3663, 0.3736],\n",
              "        [0.4168, 0.2690, 0.3142]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check that the rows add up to 1 now. Remember the reshape is just to align the rows in the attn_matrix above to the output of the cell below, but it's not doing anything to the values themselves"
      ],
      "metadata": {
        "id": "VVucaXabnDa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(attn_matrix, dim=1).reshape(-1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFZlLcddmdxJ",
        "outputId": "ee96eb67-2877-47d3-cdd9-a1148b15ea65"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This attention matrix (attn_matrix) is applied to the matrix V, and this is the actual context aware \"attention\" our model would be paying to each token in the embeding space, projected into the V space."
      ],
      "metadata": {
        "id": "ZzPtCxrTnWrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLE8Ovsjq9n_",
        "outputId": "2ee70165-c7bb-4279-b13c-ab285cc9ee12"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4043, 0.2605, 0.3352],\n",
              "        [0.2601, 0.3663, 0.3736],\n",
              "        [0.4168, 0.2690, 0.3142]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKrPXq_fpYHc",
        "outputId": "1db5de75-4dcc-41fc-a112-166de79fa1c7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7467,  0.0360, -0.5847,  0.0370],\n",
              "        [ 1.5090,  0.8009,  0.7957,  0.0151],\n",
              "        [ 0.4343,  0.9003,  0.3387,  0.2031]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.mm(attn_matrix, V)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmDnrTz1my8X",
        "outputId": "300ebb43-22b6-4336-c822-df0b8ae33490"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8405, 0.5250, 0.0844, 0.0870],\n",
              "        [0.9092, 0.6391, 0.2659, 0.0910],\n",
              "        [0.8536, 0.5133, 0.0768, 0.0833]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output matrix shows the elements of \"V\" our model is going to pay attention to. The model at this stage is just providing \"relevance\" or context awareness to the semantic meaning of the words. It's enriching the text by combining context + meaning in the V projection space!"
      ],
      "metadata": {
        "id": "v82UED4qqW3w"
      }
    }
  ]
}